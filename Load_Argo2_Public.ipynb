{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c38cf",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ac7530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b472cf2",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "091abbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43041\n",
      "55029\n",
      "43544\n",
      "24465\n",
      "25744\n",
      "11993\n",
      "11993\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./argo2/\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "    inputs = pickle.load(open(f_in, \"rb\"))\n",
    "    inputs = np.asarray(inputs)\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "#Same as get_city_trajectories, but combines the data from all cities\n",
    "def get_all_trajectories(split=\"train\", normalized=False):\n",
    "    total_inputs, total_outputs = get_city_trajectories(city=cities[0], split=split,normalized=normalized)\n",
    "    \n",
    "    for i in range(1,len(cities)):\n",
    "        city = cities[i]\n",
    "        inputs,outputs = get_city_trajectories(city=city, split=split,normalized=normalized)\n",
    "        total_inputs = np.concatenate((total_inputs,inputs))\n",
    "        \n",
    "        if total_outputs is not None:\n",
    "            total_outputs = np.concatenate((total_outputs,outputs))\n",
    "\n",
    "    return total_inputs, total_outputs\n",
    "\n",
    "def get_all_trajectories_with_city(split=\"train\", normalized=False):\n",
    "    total_inputs, total_outputs = get_city_trajectories(city=cities[0], split=split,normalized=normalized)\n",
    "    total_inputs=np.concatenate((total_inputs,indexToSizedOneHot(0,len(total_inputs))),axis=1)\n",
    "    \n",
    "    for i in range(1,len(cities)):\n",
    "        city = cities[i]\n",
    "        inputs,outputs = get_city_trajectories(city=city, split=split,normalized=normalized)\n",
    "        inputs=np.concatenate((inputs,indexToSizedOneHot(i,len(inputs))),axis=1)\n",
    "        total_inputs = np.concatenate((total_inputs,inputs))\n",
    "        \n",
    "        if total_outputs is not None:\n",
    "            total_outputs = np.concatenate((total_outputs,outputs))\n",
    "\n",
    "    return total_inputs, total_outputs\n",
    "\n",
    "def indexToOneHot(index):\n",
    "    temp = torch.zeros(6)\n",
    "    temp[index] = 1\n",
    "    return temp\n",
    "\n",
    "def indexToSizedOneHot(index,count):\n",
    "    temp = np.zeros((count,len(cities),2))\n",
    "    temp[:,index,:] = 1\n",
    "    return temp\n",
    "\n",
    "def get_category_trajectories(split=\"train\", normalized=False):\n",
    "    total_inputs, temp = get_city_trajectories(city=cities[0], split=split,normalized=normalized)\n",
    "    total_outputs = indexToOneHot(0).repeat(len(total_inputs),1)\n",
    "    \n",
    "    for i in range(1,len(cities)):\n",
    "        city = cities[i]\n",
    "        inputs,temp = get_city_trajectories(city=city, split=split,normalized=normalized)\n",
    "        total_inputs = np.concatenate((total_inputs,inputs))\n",
    "        total_outputs = np.concatenate((total_outputs,indexToOneHot(i).repeat(len(total_inputs),1)))\n",
    "\n",
    "    return total_inputs, total_outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "    \n",
    "class ArgoverseDatasetAllCities(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, split:str, transform=None):\n",
    "        super(ArgoverseDatasetAllCities, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.inputs, self.outputs = get_all_trajectories(split=split, normalized=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "    \n",
    "class ArgoverseDatasetAllCitiesWithCityIndex(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, split:str, transform=None):\n",
    "        super(ArgoverseDatasetAllCitiesWithCityIndex, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.inputs, self.outputs = get_all_trajectories_with_city(split=split, normalized=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "    \n",
    "class ArgoverseCategoryDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, split:str, transform=None):\n",
    "        super(ArgoverseCategoryDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.inputs, self.outputs = get_category_trajectories(split=split, normalized=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "for city in cities:\n",
    "    split = 'train'\n",
    "    train_dataset  = ArgoverseDataset(city = city, split = split)\n",
    "    print(len(train_dataset))\n",
    "    \n",
    "    \n",
    "city = 'palo-alto' \n",
    "split = 'train'\n",
    "train_dataset  = ArgoverseDataset(city = city, split = split)\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058453cc",
   "metadata": {},
   "source": [
    "## Create a DataLoader class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c14f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4  # batch size \n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80b5e4",
   "metadata": {},
   "source": [
    "## Sample a batch of data and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6507c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1])\n",
    "        axs[i].scatter(out[i,:,0], out[i,:,1])\n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    inp, out = sample_batch\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "      implement your Deep learning model\n",
    "      implement training routine\n",
    "    \"\"\"\n",
    "    show_sample_batch(sample_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e78c2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy.random\n",
    "\n",
    "def makeHeatmap(dataset, axis):\n",
    "    train_loader = DataLoader(dataset,batch_size=len(dataset))\n",
    "    #Heatmap of all input positions for all time steps specifically for a given dataset\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        inp, out = sample_batch\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        for i in range(len(inp[0])):\n",
    "            x = numpy.append(x,torch.squeeze(inp[:,i,0]).numpy())\n",
    "            y = numpy.append(y,torch.squeeze(inp[:,i,1]).numpy())\n",
    "\n",
    "        heatmap, xedges, yedges = np.histogram2d(x, y, bins=80)\n",
    "        extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "\n",
    "        axis.imshow(heatmap.T, extent=extent, origin='lower')\n",
    "\n",
    "split = 'train'\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "axs = axs.ravel() \n",
    "for i_city, city in enumerate(cities):\n",
    "    train_dataset  = ArgoverseDataset(city = city, split = split)\n",
    "    makeHeatmap(train_dataset, axs[i_city])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "73ff3a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "mlp = nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(112, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(32, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 120),\n",
    "                   nn.Unflatten(1,(60,2)))\n",
    "\n",
    "#From d2l's tutorial. Might be useful, but I'm ignoring it for now\n",
    "#def init_weights(m):\n",
    "#    if type(m) == nn.Linear:\n",
    "#        nn.init.normal_(m.weight, std=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "95e86940",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset  = ArgoverseDatasetAllCitiesWithCityIndex(split = \"train\")\n",
    "#full_dataset  = ArgoverseDatasetAllCities(split = \"train\")\n",
    "#Split into training and validation:\n",
    "#train_set, validation_set = torch.utils.data.random_split(full_dataset, [int(len(full_dataset)*5/6), len(full_dataset)-int(len(full_dataset)*5/6)])\n",
    "train_set = full_dataset\n",
    "#Batch size for both currently set to be the entire dataset. Might lead to problems with overfitting, but it doesn't learn anything when I don't do this\n",
    "train_loader = DataLoader(train_set,batch_size=len(train_set),shuffle=True)\n",
    "#validation_loader = DataLoader(validation_set,batch_size=len(validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4bee6161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) epoch 1, loss 106541.156965\n",
      "(train) epoch 2, loss 27038077.191506\n",
      "(train) epoch 3, loss 4710633.763159\n",
      "(train) epoch 4, loss 12819846.878047\n",
      "(train) epoch 5, loss 12351081.969149\n",
      "(train) epoch 6, loss 8532689.064490\n",
      "(train) epoch 7, loss 3147526.722299\n",
      "(train) epoch 8, loss 4260465.404875\n",
      "(train) epoch 9, loss 5975147.757742\n",
      "(train) epoch 10, loss 4698590.298073\n",
      "(train) epoch 11, loss 4816204.999961\n",
      "(train) epoch 12, loss 3935451.333831\n",
      "(train) epoch 13, loss 2596885.061192\n",
      "(train) epoch 14, loss 2634056.458139\n",
      "(train) epoch 15, loss 1745157.416022\n",
      "(train) epoch 16, loss 1517935.445461\n",
      "(train) epoch 17, loss 2716842.057071\n",
      "(train) epoch 18, loss 2387527.161911\n",
      "(train) epoch 19, loss 1685112.117125\n",
      "(train) epoch 20, loss 1235940.628488\n",
      "(train) epoch 21, loss 558632.293598\n",
      "(train) epoch 22, loss 1002302.791694\n",
      "(train) epoch 23, loss 1560069.245202\n",
      "(train) epoch 24, loss 1285809.432508\n",
      "(train) epoch 25, loss 1138021.437375\n",
      "(train) epoch 26, loss 841720.443694\n",
      "(train) epoch 27, loss 466753.685599\n",
      "(train) epoch 28, loss 703974.859206\n",
      "(train) epoch 29, loss 715748.226557\n",
      "(train) epoch 30, loss 557931.848177\n",
      "(train) epoch 31, loss 675658.970208\n",
      "(train) epoch 32, loss 543591.949445\n",
      "(train) epoch 33, loss 464436.592691\n",
      "(train) epoch 34, loss 465019.553637\n",
      "(train) epoch 35, loss 300820.950661\n",
      "(train) epoch 36, loss 366667.884602\n",
      "(train) epoch 37, loss 455699.332888\n",
      "(train) epoch 38, loss 380992.268791\n",
      "(train) epoch 39, loss 327402.004318\n",
      "(train) epoch 40, loss 241397.278486\n",
      "(train) epoch 41, loss 236586.524316\n",
      "(train) epoch 42, loss 273668.310712\n",
      "(train) epoch 43, loss 237300.876555\n",
      "(train) epoch 44, loss 237119.284060\n",
      "(train) epoch 45, loss 238331.367743\n",
      "(train) epoch 46, loss 207578.389292\n",
      "(train) epoch 47, loss 196272.246811\n",
      "(train) epoch 48, loss 167504.627389\n",
      "(train) epoch 49, loss 179912.402873\n",
      "(train) epoch 50, loss 204535.730267\n",
      "(train) epoch 51, loss 186099.670762\n",
      "(train) epoch 52, loss 170708.340228\n",
      "(train) epoch 53, loss 148906.720257\n",
      "(train) epoch 54, loss 151198.692468\n",
      "(train) epoch 55, loss 160809.358716\n",
      "(train) epoch 56, loss 151006.458845\n",
      "(train) epoch 57, loss 153770.599678\n",
      "(train) epoch 58, loss 147330.316128\n",
      "(train) epoch 59, loss 142865.604585\n",
      "(train) epoch 60, loss 136579.994191\n",
      "(train) epoch 61, loss 131512.526593\n",
      "(train) epoch 62, loss 140587.780351\n",
      "(train) epoch 63, loss 137946.339051\n",
      "(train) epoch 64, loss 133201.230286\n",
      "(train) epoch 65, loss 126119.745967\n",
      "(train) epoch 66, loss 126132.869019\n",
      "(train) epoch 67, loss 130013.313341\n",
      "(train) epoch 68, loss 126426.138085\n",
      "(train) epoch 69, loss 125483.478903\n",
      "(train) epoch 70, loss 122623.186089\n",
      "(train) epoch 71, loss 123205.544138\n",
      "(train) epoch 72, loss 121195.044314\n",
      "(train) epoch 73, loss 120662.375005\n",
      "(train) epoch 74, loss 121919.947247\n",
      "(train) epoch 75, loss 120381.163873\n",
      "(train) epoch 76, loss 118728.814853\n",
      "(train) epoch 77, loss 116459.200063\n",
      "(train) epoch 78, loss 118189.141893\n",
      "(train) epoch 79, loss 118021.174864\n",
      "(train) epoch 80, loss 117377.039997\n",
      "(train) epoch 81, loss 115939.332260\n",
      "(train) epoch 82, loss 115673.163402\n",
      "(train) epoch 83, loss 115374.106527\n",
      "(train) epoch 84, loss 114771.812694\n",
      "(train) epoch 85, loss 115069.513051\n",
      "(train) epoch 86, loss 114737.960042\n",
      "(train) epoch 87, loss 114255.411548\n",
      "(train) epoch 88, loss 113196.875613\n",
      "(train) epoch 89, loss 113543.762295\n",
      "(train) epoch 90, loss 113465.636927\n",
      "(train) epoch 91, loss 113275.603878\n",
      "(train) epoch 92, loss 112545.767241\n",
      "(train) epoch 93, loss 112517.601915\n",
      "(train) epoch 94, loss 112299.112140\n",
      "(train) epoch 95, loss 112190.972563\n",
      "(train) epoch 96, loss 111961.721082\n",
      "(train) epoch 97, loss 111812.906072\n",
      "(train) epoch 98, loss 111435.693684\n",
      "(train) epoch 99, loss 111237.792833\n",
      "(train) epoch 100, loss 111256.774031\n",
      "(train) epoch 101, loss 111181.401892\n",
      "(train) epoch 102, loss 110859.656003\n",
      "(train) epoch 103, loss 110604.429721\n",
      "(train) epoch 104, loss 110574.847588\n",
      "(train) epoch 105, loss 110515.512501\n",
      "(train) epoch 106, loss 110377.419005\n",
      "(train) epoch 107, loss 110207.934686\n",
      "(train) epoch 108, loss 110066.696079\n",
      "(train) epoch 109, loss 109929.155238\n",
      "(train) epoch 110, loss 109876.602740\n",
      "(train) epoch 111, loss 109807.741885\n",
      "(train) epoch 112, loss 109658.263689\n",
      "(train) epoch 113, loss 109498.305138\n",
      "(train) epoch 114, loss 109430.640028\n",
      "(train) epoch 115, loss 109374.721357\n",
      "(train) epoch 116, loss 109263.667779\n",
      "(train) epoch 117, loss 109150.684932\n",
      "(train) epoch 118, loss 109055.236331\n",
      "(train) epoch 119, loss 108974.970679\n",
      "(train) epoch 120, loss 108891.188130\n",
      "(train) epoch 121, loss 108820.166896\n",
      "(train) epoch 122, loss 108717.121796\n",
      "(train) epoch 123, loss 108631.470267\n",
      "(train) epoch 124, loss 108559.866232\n",
      "(train) epoch 125, loss 108502.862346\n",
      "(train) epoch 126, loss 108410.398085\n",
      "(train) epoch 127, loss 108333.448365\n",
      "(train) epoch 128, loss 108260.105978\n",
      "(train) epoch 129, loss 108198.670801\n",
      "(train) epoch 130, loss 108125.438945\n",
      "(train) epoch 131, loss 108058.356635\n",
      "(train) epoch 132, loss 107983.376379\n",
      "(train) epoch 133, loss 107916.384504\n",
      "(train) epoch 134, loss 107856.918789\n",
      "(train) epoch 135, loss 107794.237626\n",
      "(train) epoch 136, loss 107726.150489\n",
      "(train) epoch 137, loss 107659.942379\n",
      "(train) epoch 138, loss 107602.536562\n",
      "(train) epoch 139, loss 107540.418103\n",
      "(train) epoch 140, loss 107481.032775\n",
      "(train) epoch 141, loss 107419.607646\n",
      "(train) epoch 142, loss 107361.116615\n",
      "(train) epoch 143, loss 107303.017467\n",
      "(train) epoch 144, loss 107247.842368\n",
      "(train) epoch 145, loss 107190.466695\n",
      "(train) epoch 146, loss 107132.709189\n",
      "(train) epoch 147, loss 107078.870511\n",
      "(train) epoch 148, loss 107024.157632\n",
      "(train) epoch 149, loss 106969.876830\n",
      "(train) epoch 150, loss 106915.535738\n",
      "(train) epoch 151, loss 106863.254543\n",
      "(train) epoch 152, loss 106810.903011\n",
      "(train) epoch 153, loss 106760.088864\n",
      "(train) epoch 154, loss 106710.169015\n",
      "(train) epoch 155, loss 106659.887428\n",
      "(train) epoch 156, loss 106611.324096\n",
      "(train) epoch 157, loss 106562.931585\n",
      "(train) epoch 158, loss 106514.820426\n",
      "(train) epoch 159, loss 106466.719315\n",
      "(train) epoch 160, loss 106419.452212\n",
      "(train) epoch 161, loss 106372.878439\n",
      "(train) epoch 162, loss 106326.797033\n",
      "(train) epoch 163, loss 106281.479295\n",
      "(train) epoch 164, loss 106235.769675\n",
      "(train) epoch 165, loss 106190.713192\n",
      "(train) epoch 166, loss 106146.480669\n",
      "(train) epoch 167, loss 106102.770656\n",
      "(train) epoch 168, loss 106059.693684\n",
      "(train) epoch 169, loss 106017.289948\n",
      "(train) epoch 170, loss 105975.559446\n",
      "(train) epoch 171, loss 105934.210778\n",
      "(train) epoch 172, loss 105893.203752\n",
      "(train) epoch 173, loss 105852.297209\n",
      "(train) epoch 174, loss 105811.450956\n",
      "(train) epoch 175, loss 105770.855909\n",
      "(train) epoch 176, loss 105729.919221\n",
      "(train) epoch 177, loss 105688.530361\n",
      "(train) epoch 178, loss 105646.860148\n",
      "(train) epoch 179, loss 105604.416219\n",
      "(train) epoch 180, loss 105560.635868\n",
      "(train) epoch 181, loss 105514.765475\n",
      "(train) epoch 182, loss 105466.975861\n",
      "(train) epoch 183, loss 105417.689053\n",
      "(train) epoch 184, loss 105367.437610\n",
      "(train) epoch 185, loss 105317.115830\n",
      "(train) epoch 186, loss 105267.889312\n",
      "(train) epoch 187, loss 105220.592063\n",
      "(train) epoch 188, loss 105178.831417\n",
      "(train) epoch 189, loss 105134.106527\n",
      "(train) epoch 190, loss 105093.933509\n",
      "(train) epoch 191, loss 105056.523767\n",
      "(train) epoch 192, loss 105021.083487\n",
      "(train) epoch 193, loss 104986.406877\n",
      "(train) epoch 194, loss 104952.162343\n",
      "(train) epoch 195, loss 104918.400126\n",
      "(train) epoch 196, loss 104885.080033\n",
      "(train) epoch 197, loss 104852.131727\n",
      "(train) epoch 198, loss 108703.466185\n",
      "(train) epoch 199, loss 105086.296817\n",
      "(train) epoch 200, loss 105216.150724\n",
      "(train) epoch 201, loss 104995.972838\n",
      "(train) epoch 202, loss 104901.056796\n",
      "(train) epoch 203, loss 104876.820348\n",
      "(train) epoch 204, loss 104890.486007\n",
      "(train) epoch 205, loss 104832.839031\n",
      "(train) epoch 206, loss 104669.102328\n",
      "(train) epoch 207, loss 104665.384464\n",
      "(train) epoch 208, loss 104689.058209\n",
      "(train) epoch 209, loss 104591.248263\n",
      "(train) epoch 210, loss 104561.555599\n",
      "(train) epoch 211, loss 104548.522982\n",
      "(train) epoch 212, loss 104479.340582\n",
      "(train) epoch 213, loss 104447.085607\n",
      "(train) epoch 214, loss 104411.826196\n",
      "(train) epoch 215, loss 104366.418024\n",
      "(train) epoch 216, loss 104346.683204\n",
      "(train) epoch 217, loss 104308.208345\n",
      "(train) epoch 218, loss 104274.918397\n",
      "(train) epoch 219, loss 104256.811399\n",
      "(train) epoch 220, loss 104213.523413\n",
      "(train) epoch 221, loss 104181.358873\n",
      "(train) epoch 222, loss 104160.398163\n",
      "(train) epoch 223, loss 104118.145151\n",
      "(train) epoch 224, loss 104090.351611\n",
      "(train) epoch 225, loss 104073.339875\n",
      "(train) epoch 226, loss 104037.206264\n",
      "(train) epoch 227, loss 104005.071869\n",
      "(train) epoch 228, loss 103982.704400\n",
      "(train) epoch 229, loss 103956.870275\n",
      "(train) epoch 230, loss 103928.463791\n",
      "(train) epoch 231, loss 103897.474899\n",
      "(train) epoch 232, loss 103871.429760\n",
      "(train) epoch 233, loss 103847.997174\n",
      "(train) epoch 234, loss 103818.415041\n",
      "(train) epoch 235, loss 103791.465557\n",
      "(train) epoch 236, loss 103767.008046\n",
      "(train) epoch 237, loss 103739.636535\n",
      "(train) epoch 238, loss 103712.968403\n",
      "(train) epoch 239, loss 103686.450995\n",
      "(train) epoch 240, loss 103660.847981\n",
      "(train) epoch 241, loss 103634.863131\n",
      "(train) epoch 242, loss 103607.059544\n",
      "(train) epoch 243, loss 103582.531695\n",
      "(train) epoch 244, loss 103557.722495\n",
      "(train) epoch 245, loss 103530.009342\n",
      "(train) epoch 246, loss 103504.808258\n",
      "(train) epoch 247, loss 103480.270362\n",
      "(train) epoch 248, loss 103454.134788\n",
      "(train) epoch 249, loss 103428.320760\n",
      "(train) epoch 250, loss 103403.280449\n",
      "(train) epoch 251, loss 103378.541587\n",
      "(train) epoch 252, loss 103352.908427\n",
      "(train) epoch 253, loss 103327.385799\n",
      "(train) epoch 254, loss 103302.857950\n",
      "(train) epoch 255, loss 103277.526239\n",
      "(train) epoch 256, loss 103252.164384\n",
      "(train) epoch 257, loss 103227.576245\n",
      "(train) epoch 258, loss 103202.636417\n",
      "(train) epoch 259, loss 103177.515720\n",
      "(train) epoch 260, loss 103152.626133\n",
      "(train) epoch 261, loss 103127.907367\n",
      "(train) epoch 262, loss 103103.118264\n",
      "(train) epoch 263, loss 103078.278918\n",
      "(train) epoch 264, loss 103053.881697\n",
      "(train) epoch 265, loss 103029.524669\n",
      "(train) epoch 266, loss 103004.996821\n",
      "(train) epoch 267, loss 102980.710131\n",
      "(train) epoch 268, loss 102956.574165\n",
      "(train) epoch 269, loss 102932.337716\n",
      "(train) epoch 270, loss 102908.181654\n",
      "(train) epoch 271, loss 102884.136123\n",
      "(train) epoch 272, loss 102860.100640\n",
      "(train) epoch 273, loss 102836.004867\n",
      "(train) epoch 274, loss 102811.959336\n",
      "(train) epoch 275, loss 102787.974094\n",
      "(train) epoch 276, loss 102764.029046\n",
      "(train) epoch 277, loss 102740.164384\n",
      "(train) epoch 278, loss 102716.329866\n",
      "(train) epoch 279, loss 102692.475252\n",
      "(train) epoch 280, loss 102668.670880\n",
      "(train) epoch 281, loss 102644.906700\n",
      "(train) epoch 282, loss 102621.122424\n",
      "(train) epoch 283, loss 102597.267810\n",
      "(train) epoch 284, loss 102573.403148\n",
      "(train) epoch 285, loss 102549.508341\n",
      "(train) epoch 286, loss 102525.543196\n",
      "(train) epoch 287, loss 102501.568003\n",
      "(train) epoch 288, loss 102477.572713\n",
      "(train) epoch 289, loss 102453.557326\n",
      "(train) epoch 290, loss 102429.602229\n",
      "(train) epoch 291, loss 102405.667229\n",
      "(train) epoch 292, loss 102381.812615\n",
      "(train) epoch 293, loss 102358.028339\n",
      "(train) epoch 294, loss 102334.324450\n",
      "(train) epoch 295, loss 102310.700946\n",
      "(train) epoch 296, loss 102287.107587\n",
      "(train) epoch 297, loss 102263.634808\n",
      "(train) epoch 298, loss 102240.302704\n",
      "(train) epoch 299, loss 102217.121325\n",
      "(train) epoch 300, loss 102194.120815\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(mlp.parameters(),lr=0.003)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "num_epochs = 300\n",
    "\n",
    "plot_every = 2\n",
    "all_losses = []\n",
    "all_losses2 = []#validation\n",
    "total_loss = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        inp, out = sample_batch\n",
    "        inp = inp.float()\n",
    "        categories = torch.zeros(len(inp),1,2)\n",
    "        #print(inp.shape)\n",
    "        #print(torch.zeros(len(inp),1,2).shape)\n",
    "        #inp = torch.cat((inp,torch.zeros(len(inp),1,2)),dim=1)\n",
    "        #print(inp.shape)\n",
    "        #inp = torch.cat((inp,torch.zeros(1,2)))\n",
    "        #print(inp.shape)\n",
    "        out = out.float()\n",
    "        l = ((mlp(inp) - out) ** 2).sum()\n",
    "        opt.zero_grad()\n",
    "        l.backward()\n",
    "        opt.step()\n",
    "        total_loss += l.item()\n",
    "        #if i_batch % plot_every == 0 and i_batch != 0:\n",
    "            #all_losses.append(total_loss / len(train_set))\n",
    "    #for i_batch, sample_batch in enumerate(validation_loader):\n",
    "    #    inp, out = sample_batch\n",
    "    #    inp = inp.float()\n",
    "    #    out = out.float()\n",
    "    #    l = ((mlp(inp) - out) ** 2).sum()\n",
    "    #    print(f'(validation) epoch {epoch + 1}, loss {(l / len(validation_set)):f}')\n",
    "    #    all_losses2.append(l.item() / len(validation_set))\n",
    "    print(f'(train) epoch {epoch + 1}, loss {(total_loss / len(train_set)):f}')\n",
    "    all_losses.append(total_loss / len(train_set))\n",
    "    total_loss = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7d3d67b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses[70:],label=\"train\")\n",
    "\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(all_losses2[70:],label=\"validation\")\n",
    "leg = plt.legend(loc='upper center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31154db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not currently working well\n",
    "def show_sample_batch2(sample_batch,prediction):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz*2, figsize=(17, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.5)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        #axs[i].xaxis.set_ticks([])\n",
    "        #axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        #axs[i].scatter(inp[i,:,0], inp[i,:,1])\n",
    "        #if i == 0:\n",
    "            #print(inp[i,:,0])\n",
    "        axs[i].scatter(out[i,:,0], out[i,:,1])\n",
    "        #axs[i].set_title(\"hello\")\n",
    "        \n",
    "                \n",
    "    for i in range(batch_sz):\n",
    "        #axs[i+batch_sz].xaxis.set_ticks([])\n",
    "        #axs[i+batch_sz].yaxis.set_ticks([])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        #if i == 0:\n",
    "            #print(inp[i,:,0])\n",
    "        #axs[i+batch_sz].scatter(inp[i,:,0], inp[i,:,1])\n",
    "        #print(prediction[i,:,0])\n",
    "        #print(inp[i,:,0])\n",
    "        axs[i+batch_sz].scatter(prediction[i,:,0], prediction[i,:,1])\n",
    "\n",
    "    plt.tick_params(axis='both', which='both', labelsize=7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af9af9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left: ground truth, right: our prediction\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'show_sample_batch2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_84/3609643388.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#l = loss(mlp(inp) ,out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#print(l)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mshow_sample_batch2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi_batch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'show_sample_batch2' is not defined"
     ]
    }
   ],
   "source": [
    "#Validation\n",
    "\n",
    "validation_loader2 = DataLoader(validation_set,batch_size=1)\n",
    "training_loader2 = DataLoader(train_set,batch_size=1)\n",
    "print(\"Left: ground truth, right: our prediction\")\n",
    "for i_batch, sample_batch in enumerate(training_loader2):\n",
    "    inp, out = sample_batch\n",
    "    inp = inp.float()\n",
    "    out = out.float()\n",
    "    #print(inp.shape)\n",
    "    #print(out)\n",
    "    #print(mlp(inp))\n",
    "    #l = loss(mlp(inp) ,out)\n",
    "    #print(l)\n",
    "    show_sample_batch2(sample_batch,mlp(inp).detach())\n",
    "    if i_batch > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0118def7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6325\n",
      "7971\n",
      "6361\n",
      "3671\n",
      "3829\n",
      "1686\n"
     ]
    }
   ],
   "source": [
    "test_lengths = []\n",
    "for city in cities:\n",
    "    split = 'test'\n",
    "    test_dataset  = ArgoverseDataset(city = city, split = split)\n",
    "    test_lengths.append(len(test_dataset))\n",
    "    \n",
    "for le in test_lengths:\n",
    "    print(le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "72afefca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "split = 'test'\n",
    "counter = 0\n",
    "currCity = 0\n",
    "test_input, test_output = get_all_trajectories_with_city(split=\"test\", normalized=False)\n",
    "#We can't use a dataset or a dataloader because they don't work for the test set (something to do with the fact that the test set doesn't have outputs)\n",
    "\n",
    "with open('predictions.txt', 'w') as f:\n",
    "    print(\"hello\",file=f, flush=True)\n",
    "    for i_batch, curr_input in enumerate(test_input):\n",
    "        #curr_input is a numpy array, so first we need to turn it into a tensor, then add an extra dimension around it, then make it a float tensor instead of a double tensor\n",
    "        predict = mlp(torch.from_numpy(curr_input).unsqueeze(0).float())\n",
    "\n",
    "        print(\"\" + str(counter) + \"_\" + str(cities[currCity]),end='',file=f)\n",
    "        for coor in predict[0]:\n",
    "            print(\",\" + str(coor[0].item()) + \",\" + str(coor[1].item()),end='',file=f)\n",
    "        print(file=f, flush=True)\n",
    "        counter = counter+1\n",
    "        if counter >= test_lengths[currCity]:\n",
    "            counter = 0\n",
    "            currCity = currCity+1\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f17ea081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "categorize = nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(100, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(32, 6),\n",
    "                    nn.LogSoftmax(dim=1))\n",
    "\n",
    "full_dataset  = ArgoverseCategoryDataset(split = \"train\")\n",
    "#Split into training and validation:\n",
    "train_set, validation_set = torch.utils.data.random_split(full_dataset, [int(len(full_dataset)*3/6), len(full_dataset)-int(len(full_dataset)*3/6)])\n",
    "\n",
    "batch_sz = 500\n",
    "#Batch size for both currently set to be the entire dataset. Might lead to problems with overfitting, but it doesn't learn anything when I don't do this\n",
    "train_loader = DataLoader(train_set,batch_size=batch_sz,shuffle=True)\n",
    "validation_loader = DataLoader(validation_set,batch_size=len(validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50ac92b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Long but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_85/2115936147.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#print(inp.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#l = criterion(categorize(inp),torch.argmax(out,1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Long but expected Float"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(mlp.parameters(),lr=0.004)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "plot_every = 2\n",
    "all_losses = []\n",
    "all_losses2 = []#validation\n",
    "total_loss = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        #print(i_batch)\n",
    "        inp, out = sample_batch\n",
    "        inp = inp.float()\n",
    "        out = out.float()\n",
    "        #l = ((mlp(inp) - out) ** 2).sum()\n",
    "        opt.zero_grad()\n",
    "        l = 0\n",
    "        for scene in range(len(inp)):\n",
    "        #    print(categorize(inp[scene].unsqueeze(dim=0)),out[scene].unsqueeze(dim=0))\n",
    "            #print(inp[scene].shape)\n",
    "            #print(categorize(inp[scene]))\n",
    "            l += loss(categorize(inp[scene].unsqueeze(dim=0)),torch.argmax(out[scene].unsqueeze(dim=0),1))\n",
    "        #print(categorize(inp).squeeze())\n",
    "        #print(out)\n",
    "        #print(torch.argmax(out,1))\n",
    "        #print(inp.shape)\n",
    "        #l = criterion(categorize(inp),torch.argmax(out,1))\n",
    "        l.backward()\n",
    "        opt.step()\n",
    "        total_loss += l.item()\n",
    "        #if i_batch % plot_every == 0 and i_batch != 0:\n",
    "            #all_losses.append(total_loss / len(train_set))\n",
    "    print(f'(train) epoch {epoch + 1}, loss {(total_loss / len(train_set)):f}')\n",
    "    all_losses.append(total_loss / len(train_set))\n",
    "    total_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71adfc70",
   "metadata": {},
   "source": [
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "#input = torch.randn(3, 5, requires_grad=True)\n",
    "#target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "#output = loss(input, target)\n",
    "\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "output = loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ed42e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "mlps = [nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(100, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(32, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 120),\n",
    "                    nn.ELU(),\n",
    "                   nn.Unflatten(1,(60,2))),\n",
    "        nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(100, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(32, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 120),\n",
    "                    nn.ELU(),\n",
    "                   nn.Unflatten(1,(60,2))),\n",
    "        nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(100, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(32, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 120),\n",
    "                    nn.ELU(),\n",
    "                   nn.Unflatten(1,(60,2))),\n",
    "        nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(100, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(32, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 120),\n",
    "                    nn.ELU(),\n",
    "                   nn.Unflatten(1,(60,2))),\n",
    "        nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(100, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(32, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 120),\n",
    "                    nn.ELU(),\n",
    "                   nn.Unflatten(1,(60,2))),\n",
    "        nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(100, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(32, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 120),\n",
    "                    nn.ELU(),\n",
    "                   nn.Unflatten(1,(60,2))),\n",
    "        nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(100, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(32, 64),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(64, 120),\n",
    "                    nn.ELU(),\n",
    "                   nn.Unflatten(1,(60,2)))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "771ee078",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_datasets   = []\n",
    "train_sets      = []\n",
    "validation_sets = []\n",
    "for i_city, city in enumerate(cities):\n",
    "    full_datasets.append(ArgoverseDataset(city=city, split = \"train\"))\n",
    "    temp1, temp2 = torch.utils.data.random_split(full_datasets[i_city], [int(len(full_datasets[i_city])*5/6), len(full_datasets[i_city])-int(len(full_datasets[i_city])*5/6)])\n",
    "    train_sets.append(temp1)\n",
    "    validation_sets.append(temp2)\n",
    "\n",
    "#Batch size for both currently set to be the entire dataset. Might lead to problems with overfitting, but it doesn't learn anything when I don't do this\n",
    "train_loaders      = []\n",
    "validation_loaders = []\n",
    "\n",
    "for i in range(len(cities)):\n",
    "    train_loaders.append(DataLoader(train_sets[i],batch_size=len(train_sets[i]),shuffle=True))\n",
    "    validation_loaders.append(DataLoader(validation_sets[i],batch_size=len(validation_sets[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9459489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(mlp, train_loader, validation_loader, batch_sz, batch_sz_validation, num_epochs=70, loss=nn.MSELoss(), lr=0.004):\n",
    "    print(\"Starting training on a new model\")\n",
    "    opt = torch.optim.Adam(mlp.parameters(),lr=lr)\n",
    "    plot_every = 2\n",
    "    all_losses = []\n",
    "    all_losses2 = []#validation\n",
    "    total_loss = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i_batch, sample_batch in enumerate(train_loader):\n",
    "            inp, out = sample_batch\n",
    "            inp = inp.float()\n",
    "            out = out.float()\n",
    "            l = ((mlp(inp) - out) ** 2).sum()\n",
    "            opt.zero_grad()\n",
    "            l.backward()\n",
    "            opt.step()\n",
    "            total_loss += l.item()\n",
    "            #if i_batch % plot_every == 0 and i_batch != 0:\n",
    "                #all_losses.append(total_loss / len(train_set))\n",
    "        for i_batch, sample_batch in enumerate(validation_loader):\n",
    "            inp, out = sample_batch\n",
    "            inp = inp.float()\n",
    "            out = out.float()\n",
    "            l = ((mlp(inp) - out) ** 2).sum()\n",
    "            print(f'(validation) epoch {epoch + 1}, loss {(l / batch_sz_validation):f}')\n",
    "            all_losses2.append(l.item() / batch_sz_validation)\n",
    "        print(f'(train) epoch {epoch + 1}, loss {(total_loss / batch_sz):f}')\n",
    "        all_losses.append(total_loss / batch_sz)\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87277563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on a new model\n",
      "(validation) epoch 1, loss 161131504.000000\n",
      "(train) epoch 1, loss 158608163.566064\n",
      "(validation) epoch 2, loss 155394960.000000\n",
      "(train) epoch 2, loss 166601965.906488\n",
      "(validation) epoch 3, loss 157678304.000000\n",
      "(train) epoch 3, loss 160827796.095575\n",
      "(validation) epoch 4, loss 154329168.000000\n",
      "(train) epoch 4, loss 163153435.165249\n",
      "(validation) epoch 5, loss 154763920.000000\n",
      "(train) epoch 5, loss 159663726.759417\n",
      "(validation) epoch 6, loss 155592464.000000\n",
      "(train) epoch 6, loss 160119516.876460\n",
      "(validation) epoch 7, loss 154829344.000000\n",
      "(train) epoch 7, loss 161008673.774556\n",
      "(validation) epoch 8, loss 154097568.000000\n",
      "(train) epoch 8, loss 160254246.920679\n",
      "(validation) epoch 9, loss 154368992.000000\n",
      "(train) epoch 9, loss 159506953.435749\n",
      "(validation) epoch 10, loss 154609584.000000\n",
      "(train) epoch 10, loss 159777524.458695\n",
      "(validation) epoch 11, loss 153600368.000000\n",
      "(train) epoch 11, loss 160026607.669445\n",
      "(validation) epoch 12, loss 152264048.000000\n",
      "(train) epoch 12, loss 159002910.755402\n",
      "(validation) epoch 13, loss 151899728.000000\n",
      "(train) epoch 13, loss 157643492.356539\n",
      "(validation) epoch 14, loss 151796864.000000\n",
      "(train) epoch 14, loss 157277570.994173\n",
      "(validation) epoch 15, loss 151293344.000000\n",
      "(train) epoch 15, loss 157180101.108651\n",
      "(validation) epoch 16, loss 150568672.000000\n",
      "(train) epoch 16, loss 156672345.568238\n",
      "(validation) epoch 17, loss 150029360.000000\n",
      "(train) epoch 17, loss 155947080.745198\n",
      "(validation) epoch 18, loss 149273232.000000\n",
      "(train) epoch 18, loss 155421623.340452\n",
      "(validation) epoch 19, loss 147654064.000000\n",
      "(train) epoch 19, loss 154678890.534029\n",
      "(validation) epoch 20, loss 145904832.000000\n",
      "(train) epoch 20, loss 153048813.406864\n",
      "(validation) epoch 21, loss 144787216.000000\n",
      "(train) epoch 21, loss 151288786.177378\n",
      "(validation) epoch 22, loss 143453296.000000\n",
      "(train) epoch 22, loss 150179503.453537\n",
      "(validation) epoch 23, loss 142036880.000000\n",
      "(train) epoch 23, loss 148843312.356428\n",
      "(validation) epoch 24, loss 140832880.000000\n",
      "(train) epoch 24, loss 147417354.827557\n",
      "(validation) epoch 25, loss 139432896.000000\n",
      "(train) epoch 25, loss 146208891.963755\n",
      "(validation) epoch 26, loss 137541968.000000\n",
      "(train) epoch 26, loss 144789132.280035\n",
      "(validation) epoch 27, loss 136089408.000000\n",
      "(train) epoch 27, loss 142855799.267293\n",
      "(validation) epoch 28, loss 134934208.000000\n",
      "(train) epoch 28, loss 141371093.767530\n",
      "(validation) epoch 29, loss 133292824.000000\n",
      "(train) epoch 29, loss 140189658.770904\n",
      "(validation) epoch 30, loss 131892184.000000\n",
      "(train) epoch 30, loss 138505511.291828\n",
      "(validation) epoch 31, loss 130235392.000000\n",
      "(train) epoch 31, loss 137068210.536928\n",
      "(validation) epoch 32, loss 128350888.000000\n",
      "(train) epoch 32, loss 135366931.278334\n",
      "(validation) epoch 33, loss 126189240.000000\n",
      "(train) epoch 33, loss 133431507.954610\n",
      "(validation) epoch 34, loss 124408232.000000\n",
      "(train) epoch 34, loss 131209141.941506\n",
      "(validation) epoch 35, loss 122486344.000000\n",
      "(train) epoch 35, loss 129378614.223437\n",
      "(validation) epoch 36, loss 120841184.000000\n",
      "(train) epoch 36, loss 127400683.037221\n",
      "(validation) epoch 37, loss 119641752.000000\n",
      "(train) epoch 37, loss 125707034.144590\n",
      "(validation) epoch 38, loss 118889888.000000\n",
      "(train) epoch 38, loss 124472756.671035\n",
      "(validation) epoch 39, loss 118109328.000000\n",
      "(train) epoch 39, loss 123699458.548080\n",
      "(validation) epoch 40, loss 117643904.000000\n",
      "(train) epoch 40, loss 122895522.020799\n",
      "Starting training on a new model\n",
      "(validation) epoch 1, loss 548135296.000000\n",
      "(train) epoch 1, loss 552606937.787295\n",
      "(validation) epoch 2, loss 548230976.000000\n",
      "(train) epoch 2, loss 572941587.980025\n",
      "(validation) epoch 3, loss 542759296.000000\n",
      "(train) epoch 3, loss 572789298.991212\n",
      "(validation) epoch 4, loss 531863200.000000\n",
      "(train) epoch 4, loss 567456943.493731\n",
      "(validation) epoch 5, loss 541135104.000000\n",
      "(train) epoch 5, loss 556709593.999433\n",
      "(validation) epoch 6, loss 534000704.000000\n",
      "(train) epoch 6, loss 565884433.920056\n",
      "(validation) epoch 7, loss 530686464.000000\n",
      "(train) epoch 7, loss 558875664.770046\n",
      "(validation) epoch 8, loss 533420096.000000\n",
      "(train) epoch 8, loss 555586085.414397\n",
      "(validation) epoch 9, loss 533447552.000000\n",
      "(train) epoch 9, loss 558234450.382014\n",
      "(validation) epoch 10, loss 530799520.000000\n",
      "(train) epoch 10, loss 558240166.935648\n",
      "(validation) epoch 11, loss 528620064.000000\n",
      "(train) epoch 11, loss 555654272.466145\n",
      "(validation) epoch 12, loss 530522240.000000\n",
      "(train) epoch 12, loss 553547836.783043\n",
      "(validation) epoch 13, loss 531089344.000000\n",
      "(train) epoch 13, loss 555447378.957019\n",
      "(validation) epoch 14, loss 529471648.000000\n",
      "(train) epoch 14, loss 555995939.443749\n",
      "(validation) epoch 15, loss 528468576.000000\n",
      "(train) epoch 15, loss 554392057.423730\n",
      "(validation) epoch 16, loss 528379584.000000\n",
      "(train) epoch 16, loss 553396188.048237\n",
      "(validation) epoch 17, loss 528988416.000000\n",
      "(train) epoch 17, loss 553295302.309702\n",
      "(validation) epoch 18, loss 528207200.000000\n",
      "(train) epoch 18, loss 553891561.719956\n",
      "(validation) epoch 19, loss 527368864.000000\n",
      "(train) epoch 19, loss 553122433.727806\n",
      "(validation) epoch 20, loss 527888896.000000\n",
      "(train) epoch 20, loss 552294813.958872\n",
      "(validation) epoch 21, loss 528207296.000000\n",
      "(train) epoch 21, loss 552808937.926511\n",
      "(validation) epoch 22, loss 527873536.000000\n",
      "(train) epoch 22, loss 553124583.151972\n",
      "(validation) epoch 23, loss 527004448.000000\n",
      "(train) epoch 23, loss 552794760.873498\n",
      "(validation) epoch 24, loss 526877024.000000\n",
      "(train) epoch 24, loss 551932978.980047\n",
      "(validation) epoch 25, loss 527302208.000000\n",
      "(train) epoch 25, loss 551802001.303182\n",
      "(validation) epoch 26, loss 527220288.000000\n",
      "(train) epoch 26, loss 552219355.450902\n",
      "(validation) epoch 27, loss 526989056.000000\n",
      "(train) epoch 27, loss 552141107.264758\n",
      "(validation) epoch 28, loss 526814368.000000\n",
      "(train) epoch 28, loss 551917247.024446\n",
      "(validation) epoch 29, loss 526880672.000000\n",
      "(train) epoch 29, loss 551746573.599145\n",
      "(validation) epoch 30, loss 526862752.000000\n",
      "(train) epoch 30, loss 551811788.043003\n",
      "(validation) epoch 31, loss 526577856.000000\n",
      "(train) epoch 31, loss 551793266.409229\n",
      "(validation) epoch 32, loss 526571104.000000\n",
      "(train) epoch 32, loss 551510868.659703\n",
      "(validation) epoch 33, loss 526661248.000000\n",
      "(train) epoch 33, loss 551503185.611619\n",
      "(validation) epoch 34, loss 526701472.000000\n",
      "(train) epoch 34, loss 551588796.718843\n",
      "(validation) epoch 35, loss 526541760.000000\n",
      "(train) epoch 35, loss 551626205.845825\n",
      "(validation) epoch 36, loss 526419904.000000\n",
      "(train) epoch 36, loss 551471721.700417\n",
      "(validation) epoch 37, loss 526496960.000000\n",
      "(train) epoch 37, loss 551355652.795429\n",
      "(validation) epoch 38, loss 526484512.000000\n",
      "(train) epoch 38, loss 551432437.543843\n",
      "(validation) epoch 39, loss 526423904.000000\n",
      "(train) epoch 39, loss 551420181.252851\n",
      "(validation) epoch 40, loss 526338624.000000\n",
      "(train) epoch 40, loss 551361140.686918\n",
      "Starting training on a new model\n",
      "(validation) epoch 1, loss 85271128.000000\n",
      "(train) epoch 1, loss 58840364.997189\n",
      "(validation) epoch 2, loss 101260248.000000\n",
      "(train) epoch 2, loss 85773573.150196\n",
      "(validation) epoch 3, loss 60187548.000000\n",
      "(train) epoch 3, loss 101145205.763104\n",
      "(validation) epoch 4, loss 81856960.000000\n",
      "(train) epoch 4, loss 60344254.190376\n",
      "(validation) epoch 5, loss 83512000.000000\n",
      "(train) epoch 5, loss 82207508.812435\n",
      "(validation) epoch 6, loss 66609276.000000\n",
      "(train) epoch 6, loss 83828667.819875\n",
      "(validation) epoch 7, loss 61395704.000000\n",
      "(train) epoch 7, loss 66834272.386265\n",
      "(validation) epoch 8, loss 68018168.000000\n",
      "(train) epoch 8, loss 61563094.473902\n",
      "(validation) epoch 9, loss 66116732.000000\n",
      "(train) epoch 9, loss 68175840.506201\n",
      "(validation) epoch 10, loss 62745928.000000\n",
      "(train) epoch 10, loss 66288253.439012\n",
      "(validation) epoch 11, loss 64425000.000000\n",
      "(train) epoch 11, loss 62944721.803450\n",
      "(validation) epoch 12, loss 64132368.000000\n",
      "(train) epoch 12, loss 64633927.284352\n",
      "(validation) epoch 13, loss 58841176.000000\n",
      "(train) epoch 13, loss 64318185.579011\n",
      "(validation) epoch 14, loss 54952964.000000\n",
      "(train) epoch 14, loss 58988685.214132\n",
      "(validation) epoch 15, loss 58084284.000000\n",
      "(train) epoch 15, loss 55087416.680373\n",
      "(validation) epoch 16, loss 61827168.000000\n",
      "(train) epoch 16, loss 58240170.393871\n",
      "(validation) epoch 17, loss 59400844.000000\n",
      "(train) epoch 17, loss 61999505.066196\n",
      "(validation) epoch 18, loss 56281156.000000\n",
      "(train) epoch 18, loss 59568218.079039\n",
      "(validation) epoch 19, loss 56774008.000000\n",
      "(train) epoch 19, loss 56442808.659207\n",
      "(validation) epoch 20, loss 57855468.000000\n",
      "(train) epoch 20, loss 56943332.047842\n",
      "(validation) epoch 21, loss 57061548.000000\n",
      "(train) epoch 21, loss 58032801.673814\n",
      "(validation) epoch 22, loss 56166972.000000\n",
      "(train) epoch 22, loss 57230884.206581\n",
      "(validation) epoch 23, loss 56802948.000000\n",
      "(train) epoch 23, loss 56310743.306399\n",
      "(validation) epoch 24, loss 57004788.000000\n",
      "(train) epoch 24, loss 56925148.273163\n",
      "(validation) epoch 25, loss 55374416.000000\n",
      "(train) epoch 25, loss 57125628.543019\n",
      "(validation) epoch 26, loss 54359344.000000\n",
      "(train) epoch 26, loss 55504632.084220\n",
      "(validation) epoch 27, loss 55276304.000000\n",
      "(train) epoch 27, loss 54503014.580610\n",
      "(validation) epoch 28, loss 55917868.000000\n",
      "(train) epoch 28, loss 55432102.880450\n",
      "(validation) epoch 29, loss 55428044.000000\n",
      "(train) epoch 29, loss 56076973.074795\n",
      "(validation) epoch 30, loss 55023160.000000\n",
      "(train) epoch 30, loss 55584721.605909\n",
      "(validation) epoch 31, loss 55125028.000000\n",
      "(train) epoch 31, loss 55177551.708097\n",
      "(validation) epoch 32, loss 54902852.000000\n",
      "(train) epoch 32, loss 55276413.791765\n",
      "(validation) epoch 33, loss 54541120.000000\n",
      "(train) epoch 33, loss 55050388.099873\n",
      "(validation) epoch 34, loss 54741204.000000\n",
      "(train) epoch 34, loss 54687341.127708\n",
      "(validation) epoch 35, loss 55074216.000000\n",
      "(train) epoch 35, loss 54891863.440445\n",
      "(validation) epoch 36, loss 54816304.000000\n",
      "(train) epoch 36, loss 55229010.995756\n",
      "(validation) epoch 37, loss 54315108.000000\n",
      "(train) epoch 37, loss 54968965.679325\n",
      "(validation) epoch 38, loss 54257540.000000\n",
      "(train) epoch 38, loss 54461080.643334\n",
      "(validation) epoch 39, loss 54447040.000000\n",
      "(train) epoch 39, loss 54398770.330816\n",
      "(validation) epoch 40, loss 54428756.000000\n",
      "(train) epoch 40, loss 54588609.082952\n",
      "Starting training on a new model\n",
      "(validation) epoch 1, loss 2383835392.000000\n",
      "(train) epoch 1, loss 2131822540.265071\n",
      "(validation) epoch 2, loss 2017617792.000000\n",
      "(train) epoch 2, loss 2353457365.067543\n",
      "(validation) epoch 3, loss 2085817088.000000\n",
      "(train) epoch 3, loss 1990878948.412224\n",
      "(validation) epoch 4, loss 2146819328.000000\n",
      "(train) epoch 4, loss 2057806560.544661\n",
      "(validation) epoch 5, loss 2083937792.000000\n",
      "(train) epoch 5, loss 2117872524.224261\n",
      "(validation) epoch 6, loss 1997320576.000000\n",
      "(train) epoch 6, loss 2055649231.278756\n",
      "(validation) epoch 7, loss 1995479936.000000\n",
      "(train) epoch 7, loss 1969866693.032226\n",
      "(validation) epoch 8, loss 2021402752.000000\n",
      "(train) epoch 8, loss 1968025783.031147\n",
      "(validation) epoch 9, loss 1982364032.000000\n",
      "(train) epoch 9, loss 1993718080.957473\n",
      "(validation) epoch 10, loss 1940326272.000000\n",
      "(train) epoch 10, loss 1954980586.188453\n",
      "(validation) epoch 11, loss 1953825920.000000\n",
      "(train) epoch 11, loss 1913119222.682690\n",
      "(validation) epoch 12, loss 1947949184.000000\n",
      "(train) epoch 12, loss 1926384966.633247\n",
      "(validation) epoch 13, loss 1937586816.000000\n",
      "(train) epoch 13, loss 1920752580.278805\n",
      "(validation) epoch 14, loss 1925559552.000000\n",
      "(train) epoch 14, loss 1910438094.035611\n",
      "(validation) epoch 15, loss 1933269248.000000\n",
      "(train) epoch 15, loss 1898319318.486486\n",
      "(validation) epoch 16, loss 1922461056.000000\n",
      "(train) epoch 16, loss 1906021391.319566\n",
      "(validation) epoch 17, loss 1909182976.000000\n",
      "(train) epoch 17, loss 1895223429.606710\n",
      "(validation) epoch 18, loss 1900889984.000000\n",
      "(train) epoch 18, loss 1882019405.928876\n",
      "(validation) epoch 19, loss 1898896384.000000\n",
      "(train) epoch 19, loss 1873854431.050375\n",
      "(validation) epoch 20, loss 1893730432.000000\n",
      "(train) epoch 20, loss 1871865803.863246\n",
      "(validation) epoch 21, loss 1883779840.000000\n",
      "(train) epoch 21, loss 1866733557.452102\n",
      "(validation) epoch 22, loss 1881523072.000000\n",
      "(train) epoch 22, loss 1856897197.588267\n",
      "(validation) epoch 23, loss 1881063680.000000\n",
      "(train) epoch 23, loss 1854675679.238731\n",
      "(validation) epoch 24, loss 1878739328.000000\n",
      "(train) epoch 24, loss 1854190763.629372\n",
      "(validation) epoch 25, loss 1875324672.000000\n",
      "(train) epoch 25, loss 1851824614.107421\n",
      "(validation) epoch 26, loss 1876341888.000000\n",
      "(train) epoch 26, loss 1848426913.094031\n",
      "(validation) epoch 27, loss 1876690560.000000\n",
      "(train) epoch 27, loss 1849468957.031834\n",
      "(validation) epoch 28, loss 1874011264.000000\n",
      "(train) epoch 28, loss 1849795251.540295\n",
      "(validation) epoch 29, loss 1872029184.000000\n",
      "(train) epoch 29, loss 1847079353.806249\n",
      "(validation) epoch 30, loss 1870977280.000000\n",
      "(train) epoch 30, loss 1845086817.668514\n",
      "(validation) epoch 31, loss 1870098048.000000\n",
      "(train) epoch 31, loss 1844047654.010104\n",
      "(validation) epoch 32, loss 1868605568.000000\n",
      "(train) epoch 32, loss 1843184393.128955\n",
      "(validation) epoch 33, loss 1868458496.000000\n",
      "(train) epoch 33, loss 1841686030.641487\n",
      "(validation) epoch 34, loss 1868586496.000000\n",
      "(train) epoch 34, loss 1841509716.395742\n",
      "(validation) epoch 35, loss 1868319488.000000\n",
      "(train) epoch 35, loss 1841630893.864522\n",
      "(validation) epoch 36, loss 1867860224.000000\n",
      "(train) epoch 36, loss 1841365908.160298\n",
      "(validation) epoch 37, loss 1867651328.000000\n",
      "(train) epoch 37, loss 1840915555.903664\n",
      "(validation) epoch 38, loss 1867230208.000000\n",
      "(train) epoch 38, loss 1840721137.044587\n",
      "(validation) epoch 39, loss 1866986752.000000\n",
      "(train) epoch 39, loss 1840299587.581890\n",
      "(validation) epoch 40, loss 1866363264.000000\n",
      "(train) epoch 40, loss 1840057232.644332\n",
      "Starting training on a new model\n",
      "(validation) epoch 1, loss 1187990784.000000\n",
      "(train) epoch 1, loss 1289206327.154617\n",
      "(validation) epoch 2, loss 1023002304.000000\n",
      "(train) epoch 2, loss 1186667686.728756\n",
      "(validation) epoch 3, loss 797476864.000000\n",
      "(train) epoch 3, loss 1021987146.975435\n",
      "(validation) epoch 4, loss 585185600.000000\n",
      "(train) epoch 4, loss 796864238.780590\n",
      "(validation) epoch 5, loss 553842368.000000\n",
      "(train) epoch 5, loss 584951247.336969\n",
      "(validation) epoch 6, loss 549230976.000000\n",
      "(train) epoch 6, loss 553595633.214935\n",
      "(validation) epoch 7, loss 413439136.000000\n",
      "(train) epoch 7, loss 548892168.902065\n",
      "(validation) epoch 8, loss 301431264.000000\n",
      "(train) epoch 8, loss 413282595.930453\n",
      "(validation) epoch 9, loss 267216000.000000\n",
      "(train) epoch 9, loss 301456191.018506\n",
      "(validation) epoch 10, loss 269841472.000000\n",
      "(train) epoch 10, loss 267276636.063581\n",
      "(validation) epoch 11, loss 271770400.000000\n",
      "(train) epoch 11, loss 269869335.901925\n",
      "(validation) epoch 12, loss 265798560.000000\n",
      "(train) epoch 12, loss 271763107.268168\n",
      "(validation) epoch 13, loss 259128240.000000\n",
      "(train) epoch 13, loss 265758148.644945\n",
      "(validation) epoch 14, loss 259594464.000000\n",
      "(train) epoch 14, loss 259044168.278562\n",
      "(validation) epoch 15, loss 262806176.000000\n",
      "(train) epoch 15, loss 259452298.125204\n",
      "(validation) epoch 16, loss 256428272.000000\n",
      "(train) epoch 16, loss 262623369.277956\n",
      "(validation) epoch 17, loss 240249872.000000\n",
      "(train) epoch 17, loss 256253000.027968\n",
      "(validation) epoch 18, loss 223259200.000000\n",
      "(train) epoch 18, loss 240119211.728709\n",
      "(validation) epoch 19, loss 211299248.000000\n",
      "(train) epoch 19, loss 223177863.989186\n",
      "(validation) epoch 20, loss 202267968.000000\n",
      "(train) epoch 20, loss 211260203.639211\n",
      "(validation) epoch 21, loss 189588720.000000\n",
      "(train) epoch 21, loss 202260146.256095\n",
      "(validation) epoch 22, loss 175041440.000000\n",
      "(train) epoch 22, loss 189611884.602806\n",
      "(validation) epoch 23, loss 163746704.000000\n",
      "(train) epoch 23, loss 175086164.557684\n",
      "(validation) epoch 24, loss 158724320.000000\n",
      "(train) epoch 24, loss 163803647.116953\n",
      "(validation) epoch 25, loss 154008320.000000\n",
      "(train) epoch 25, loss 158782159.229572\n",
      "(validation) epoch 26, loss 147252816.000000\n",
      "(train) epoch 26, loss 154080869.979956\n",
      "(validation) epoch 27, loss 141265392.000000\n",
      "(train) epoch 27, loss 147342805.064839\n",
      "(validation) epoch 28, loss 138341664.000000\n",
      "(train) epoch 28, loss 141381213.292686\n",
      "(validation) epoch 29, loss 135239584.000000\n",
      "(train) epoch 29, loss 138476795.119377\n",
      "(validation) epoch 30, loss 129597184.000000\n",
      "(train) epoch 30, loss 135386738.963129\n",
      "(validation) epoch 31, loss 124841576.000000\n",
      "(train) epoch 31, loss 129757834.113271\n",
      "(validation) epoch 32, loss 121209464.000000\n",
      "(train) epoch 32, loss 125007410.429124\n",
      "(validation) epoch 33, loss 117282672.000000\n",
      "(train) epoch 33, loss 121377816.391181\n",
      "(validation) epoch 34, loss 112842272.000000\n",
      "(train) epoch 34, loss 117452096.044749\n",
      "(validation) epoch 35, loss 109167592.000000\n",
      "(train) epoch 35, loss 113012352.041766\n",
      "(validation) epoch 36, loss 106584232.000000\n",
      "(train) epoch 36, loss 109336128.557871\n",
      "(validation) epoch 37, loss 104113464.000000\n",
      "(train) epoch 37, loss 106747387.823428\n",
      "(validation) epoch 38, loss 101416704.000000\n",
      "(train) epoch 38, loss 104269917.459749\n",
      "(validation) epoch 39, loss 99257736.000000\n",
      "(train) epoch 39, loss 101566820.941780\n",
      "(validation) epoch 40, loss 97942280.000000\n",
      "(train) epoch 40, loss 99400928.389316\n",
      "Starting training on a new model\n",
      "(validation) epoch 1, loss 273758528.000000\n",
      "(train) epoch 1, loss 278758641.604163\n",
      "(validation) epoch 2, loss 262715392.000000\n",
      "(train) epoch 2, loss 272011725.486492\n",
      "(validation) epoch 3, loss 245188384.000000\n",
      "(train) epoch 3, loss 260962096.208125\n",
      "(validation) epoch 4, loss 222601632.000000\n",
      "(train) epoch 4, loss 243405241.813888\n",
      "(validation) epoch 5, loss 199714000.000000\n",
      "(train) epoch 5, loss 220775268.873324\n",
      "(validation) epoch 6, loss 189453600.000000\n",
      "(train) epoch 6, loss 197801654.893736\n",
      "(validation) epoch 7, loss 189017424.000000\n",
      "(train) epoch 7, loss 187422572.865319\n",
      "(validation) epoch 8, loss 178076064.000000\n",
      "(train) epoch 8, loss 186982903.290774\n",
      "(validation) epoch 9, loss 164180288.000000\n",
      "(train) epoch 9, loss 176100032.115269\n",
      "(validation) epoch 10, loss 158308464.000000\n",
      "(train) epoch 10, loss 162259253.843506\n",
      "(validation) epoch 11, loss 159230592.000000\n",
      "(train) epoch 11, loss 156374430.559135\n",
      "(validation) epoch 12, loss 159225168.000000\n",
      "(train) epoch 12, loss 157258792.779668\n",
      "(validation) epoch 13, loss 156599184.000000\n",
      "(train) epoch 13, loss 157245848.206524\n",
      "(validation) epoch 14, loss 154346848.000000\n",
      "(train) epoch 14, loss 154651962.966580\n",
      "(validation) epoch 15, loss 154720032.000000\n",
      "(train) epoch 15, loss 152482455.130678\n",
      "(validation) epoch 16, loss 155906592.000000\n",
      "(train) epoch 16, loss 152934308.604363\n",
      "(validation) epoch 17, loss 155077808.000000\n",
      "(train) epoch 17, loss 154154901.849910\n",
      "(validation) epoch 18, loss 152963344.000000\n",
      "(train) epoch 18, loss 153318750.623174\n",
      "(validation) epoch 19, loss 151786704.000000\n",
      "(train) epoch 19, loss 151172377.769061\n",
      "(validation) epoch 20, loss 151597232.000000\n",
      "(train) epoch 20, loss 149965594.691215\n",
      "(validation) epoch 21, loss 151409472.000000\n",
      "(train) epoch 21, loss 149770468.694016\n",
      "(validation) epoch 22, loss 150767568.000000\n",
      "(train) epoch 22, loss 149596549.763458\n",
      "(validation) epoch 23, loss 149638256.000000\n",
      "(train) epoch 23, loss 148976482.414249\n",
      "(validation) epoch 24, loss 148907232.000000\n",
      "(train) epoch 24, loss 147868088.584351\n",
      "(validation) epoch 25, loss 148843520.000000\n",
      "(train) epoch 25, loss 147152386.151691\n",
      "(validation) epoch 26, loss 149018096.000000\n",
      "(train) epoch 26, loss 147101316.072844\n",
      "(validation) epoch 27, loss 148636608.000000\n",
      "(train) epoch 27, loss 147288074.655994\n",
      "(validation) epoch 28, loss 148102960.000000\n",
      "(train) epoch 28, loss 146917823.141885\n",
      "(validation) epoch 29, loss 147894080.000000\n",
      "(train) epoch 29, loss 146388787.486892\n",
      "(validation) epoch 30, loss 148023104.000000\n",
      "(train) epoch 30, loss 146176139.757454\n",
      "(validation) epoch 31, loss 148065600.000000\n",
      "(train) epoch 31, loss 146298608.272163\n",
      "(validation) epoch 32, loss 147814016.000000\n",
      "(train) epoch 32, loss 146338687.923154\n",
      "(validation) epoch 33, loss 147472336.000000\n",
      "(train) epoch 33, loss 146092321.351211\n",
      "(validation) epoch 34, loss 147339552.000000\n",
      "(train) epoch 34, loss 145758149.392035\n",
      "(validation) epoch 35, loss 147427472.000000\n",
      "(train) epoch 35, loss 145630539.770262\n",
      "(validation) epoch 36, loss 147458928.000000\n",
      "(train) epoch 36, loss 145721217.357615\n",
      "(validation) epoch 37, loss 147306352.000000\n",
      "(train) epoch 37, loss 145752588.602762\n",
      "(validation) epoch 38, loss 147157168.000000\n",
      "(train) epoch 38, loss 145597306.185311\n",
      "(validation) epoch 39, loss 147151808.000000\n",
      "(train) epoch 39, loss 145443820.532319\n",
      "(validation) epoch 40, loss 147192784.000000\n",
      "(train) epoch 40, loss 145434613.753852\n"
     ]
    }
   ],
   "source": [
    "loss=nn.MSELoss()\n",
    "num_epochs = 40\n",
    "lr=0.004\n",
    "\n",
    "for i in range(len(cities)):\n",
    "    train_loop(mlps[i],train_loaders[i],validation_loaders[i],len(train_sets[i]),len(validation_sets[i]),num_epochs,loss,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66d2ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "split = 'test'\n",
    "counter = 0\n",
    "currCity = 0\n",
    "test_input, test_output = get_all_trajectories(split=\"test\", normalized=False)\n",
    "#We can't use a dataset or a dataloader because they don't work for the test set (something to do with the fact that the test set doesn't have outputs)\n",
    "\n",
    "with open('predictions.txt', 'w') as f:\n",
    "    print(\"hello\",file=f, flush=True)\n",
    "    for i_batch, curr_input in enumerate(test_input):\n",
    "        #curr_input is a numpy array, so first we need to turn it into a tensor, then add an extra dimension around it, then make it a float tensor instead of a double tensor\n",
    "        predict = mlps[currCity](torch.from_numpy(curr_input).unsqueeze(0).float())\n",
    "\n",
    "        print(\"\" + str(counter) + \"_\" + str(cities[currCity]),end='',file=f)\n",
    "        for coor in predict[0]:\n",
    "            print(\",\" + str(coor[0].item()) + \",\" + str(coor[1].item()),end='',file=f)\n",
    "        print(file=f, flush=True)\n",
    "        counter = counter+1\n",
    "        if counter >= test_lengths[currCity]:\n",
    "            counter = 0\n",
    "            currCity = currCity+1\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f804003a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 51, 2)\n"
     ]
    }
   ],
   "source": [
    "temp1 = np.zeros((5,50,2))\n",
    "temp2 = np.zeros((5,1,2))\n",
    "print(np.concatenate((temp1,temp2),axis=1).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf8b574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
